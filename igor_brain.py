# igor_brain.py
import os
import re
import json
import hashlib
import requests
import threading
from functools import lru_cache
import unicodedata
import string
import time
import subprocess
import igor_skills as skills
import igor_config
import igor_globals
from igor_system import INSTALLED_APPS, APP_METADATA

def call_llm_api(prompt, n_predict=150, stop=None, temperature=0.1, grammar=None):
    """
    Fonction unifiÃ©e pour appeler le LLM avec gestion de fallback automatique.
    Si le premier modÃ¨le Ã©choue, passe au suivant dans la liste configurÃ©e.
    """
    if stop is None:
        stop = ["User:", "\n\n"]

    # 1. Construction de la liste des candidats (Config actuelle + Instances enregistrÃ©es)
    candidates = []
    
    # A. Configuration actuelle (Prioritaire)
    candidates.append({
        'type': skills.MEMORY.get('llm_backend', 'llamacpp'),
        'url': skills.MEMORY.get('llm_api_url', igor_globals.API_URL),
        'model_name': skills.MEMORY.get('llm_model_name', 'mistral-small'),
        'is_current': True
    })

    # B. Autres instances disponibles (Fallback)
    instances = skills.MEMORY.get('llm_instances', [])
    for inst in instances:
        if inst.get('enabled', True):
            # On Ã©vite d'ajouter le doublon de la config actuelle
            if inst.get('url') == candidates[0]['url'] and \
               inst.get('model_name') == candidates[0]['model_name']:
                continue
            inst_copy = inst.copy()
            inst_copy['is_current'] = False
            candidates.append(inst_copy)

    # 2. Boucle de tentative
    for i, candidate in enumerate(candidates):
        backend = candidate.get('type', 'llamacpp')
        url = candidate.get('url')
        model_name = candidate.get('model_name')
        
        # Log discret sauf si switch
        if i > 0:
            print(f"  [LLM] ðŸ”„ Tentative fallback sur : {backend} ({model_name or 'Local'})...", flush=True)

        # --- DÃ‰TECTION MODÃˆLE RAISONNEMENT (DEEPSEEK R1) ---
        # Si le nom contient 'r1' ou 'deepseek', on augmente massivement le budget tokens et le timeout
        is_reasoning = False
        if model_name:
            lower_name = model_name.lower()
            if "r1" in lower_name or "deepseek" in lower_name or "reason" in lower_name:
                is_reasoning = True

        # Ajustement des limites pour laisser le modÃ¨le "penser"
        effective_n_predict = n_predict
        current_timeout = 300.0

        if is_reasoning:
            # On laisse au moins 2048 tokens pour la pensÃ©e + le JSON
            effective_n_predict = max(n_predict, 2048)
            current_timeout = 600.0 # 10 minutes max, la pensÃ©e peut Ãªtre lente sur CPU
            # Pour DeepSeek, une tempÃ©rature un peu plus Ã©levÃ©e aide parfois la crÃ©ativitÃ© logique
            # mais pour du JSON strict, on reste bas (0.1 ou 0.6 recommandÃ© pour R1)
            temperature = 0.6 

        if backend == 'ollama':
            # Format API Ollama (/api/generate)
            payload = {
                "model": model_name,
                "prompt": prompt,
                "stream": False,
                "options": {
                    "num_predict": effective_n_predict, # Utilisation de la valeur ajustÃ©e
                    "temperature": temperature,
                    "stop": stop
                }
            }
            
            # Optionnel : Forcer le mode JSON pour Ollama si ce n'est PAS un modÃ¨le R1
            # (R1 gÃ¨re mal le format:json natif car il veut output <think> qui n'est pas du JSON)
            if not is_reasoning:
                payload["format"] = "json"

        else:
            # Format API Llama.cpp Server (/completion)
            # Llama.cpp gÃ¨re le grammar, donc pas besoin d'augmenter n_predict artificiellement
            # sauf si on utilisait un GGUF R1 (support encore expÃ©rimental pour grammar + think)
            payload = {
                "prompt": prompt,
                "n_predict": n_predict, # On garde la valeur standard pour Llama.cpp pour l'instant
                "temperature": temperature,
                "stop": stop
            }
            if grammar and not is_reasoning:
                payload["grammar"] = grammar

        try:
            # Utilisation de l'URL configurÃ©e (Llama.cpp ou Ollama)
            res = requests.post(url, json=payload, timeout=current_timeout)
            
            if res.status_code == 200:
                data = res.json()
                
                # SI SUCCESS SUR UN FALLBACK -> MISE Ã€ JOUR DE LA CONFIGURATION
                if not candidate.get('is_current'):
                    print(f"  [LLM] âœ… Nouveau modÃ¨le actif : {model_name or backend}", flush=True)
                    skills.MEMORY['llm_backend'] = backend
                    skills.MEMORY['llm_api_url'] = url
                    if model_name:
                        skills.MEMORY['llm_model_name'] = model_name
                    skills.save_memory(skills.MEMORY)

                # Normalisation de la rÃ©ponse
                if backend == 'ollama':
                    return data.get('response', '').strip()
                else:
                    return data.get('content', '').strip()
            else:
                print(f"  [LLM] âš ï¸ Erreur {res.status_code} sur {model_name or url}: {res.text}", flush=True)
                # On continue vers le prochain candidat
        except Exception as e:
            print(f"  [LLM] âš ï¸ Exception sur {model_name or url}: {e}", flush=True)
            # On continue vers le prochain candidat

    print("  [LLM] âŒ CRITIQUE : Tous les modÃ¨les ont Ã©chouÃ©.", flush=True)
    return None
    
def check_llama_status():
    """VÃ©rifie si le serveur local llama.cpp rÃ©pond (Port 8080)."""
    try:
        requests.get("http://localhost:8080/health", timeout=0.2)
        return True
    except:
        return False

def check_ollama_status():
    """VÃ©rifie si Ollama rÃ©pond (Port 11434)."""
    try:
        requests.get("http://localhost:11434/", timeout=0.2)
        return True
    except:
        return False

def manage_local_server(action):
    """DÃ©marre ou arrÃªte le serveur llama.cpp local."""
    if action == "stop":
        if igor_globals.LLM_SERVER_PROCESS:
            print("  [LLM-SRV] ArrÃªt du serveur...", flush=True)
            igor_globals.LLM_SERVER_PROCESS.terminate()
            try:
                igor_globals.LLM_SERVER_PROCESS.wait(timeout=2)
            except:
                igor_globals.LLM_SERVER_PROCESS.kill()
            igor_globals.LLM_SERVER_PROCESS = None
        return False

    elif action == "start":
        if igor_globals.LLM_SERVER_PROCESS:
            return True # DÃ©jÃ  lancÃ©

        # FIX : Gestion propre des chemins (expanduser pour le ~)
        binary = os.path.expanduser(skills.MEMORY.get('llm_binary_path', '')).strip()
        model = os.path.expanduser(skills.MEMORY.get('llm_gguf_path', '')).strip()
        
        # VÃ‰RIFICATION DÃ‰TAILLÃ‰E (Pour savoir quel fichier manque)
        missing = False
        
        if not binary:
            print("  [LLM-SRV] âŒ Config: Chemin binaire vide.", flush=True)
            missing = True
        elif not os.path.isfile(binary):
            print(f"  [LLM-SRV] âŒ FICHIER BINAIRE INTROUVABLE :\n    Attendu: '{binary}'\n    Conseil: Avez-vous compilÃ© llama.cpp ? (make)", flush=True)
            missing = True
        elif not os.access(binary, os.X_OK):
            print(f"  [LLM-SRV] âš ï¸ Permission refusÃ©e : '{binary}' n'est pas exÃ©cutable.\n    Tentative de correction (chmod +x)...", flush=True)
            try:
                os.chmod(binary, 0o755)
            except Exception as e:
                print(f"    Echec chmod: {e}")
                missing = True

        if not model:
            print("  [LLM-SRV] âŒ Config: Chemin modÃ¨le vide.", flush=True)
            missing = True
        elif not os.path.isfile(model):
            print(f"  [LLM-SRV] âŒ FICHIER MODÃˆLE INTROUVABLE :\n    Attendu: '{model}'\n    Conseil: VÃ©rifiez le nom exact du fichier.", flush=True)
            missing = True

        if missing:
            return False

        try:
            print(f"  [LLM-SRV] DÃ©marrage : {os.path.basename(binary)} sur {os.path.basename(model)}", flush=True)
            
            # Commande de dÃ©marrage standard
            cmd = [
                binary,
                "-m", model,
                "-c", "8192",      # Contexte augmentÃ© (8k standard ajd)
                "--port", "8080",
                "-ngl", "99",      # GPU Layers
                "--host", "0.0.0.0"
            ]
            
            # DEBUG : Affichage de la commande complÃ¨te
            import shlex
            cmd_str = ' '.join(shlex.quote(s) for s in cmd)
            print(f"  [LLM-SRV] ðŸ“Ÿ COMMANDE LANCÃ‰E :\n{cmd_str}", flush=True)
            
            # Lancement avec capture des erreurs (stderr=PIPE)
            # On utilise text=True pour recevoir des chaÃ®nes de caractÃ¨res
            igor_globals.LLM_SERVER_PROCESS = subprocess.Popen(
                cmd, 
                stdout=subprocess.DEVNULL, 
                stderr=subprocess.PIPE, # On capture les erreurs
                text=True
            )
            
            # VÃ‰RIFICATION IMMÃ‰DIATE (0.5s)
            # On attend un instant pour voir si le processus crash tout de suite
            try:
                ret_code = igor_globals.LLM_SERVER_PROCESS.wait(timeout=0.5)
                
                # Si on arrive ici, c'est que le processus s'est ARRÃŠTÃ‰ (Crash)
                _, stderr_output = igor_globals.LLM_SERVER_PROCESS.communicate()
                print(f"  [LLM-SRV] âŒ CRASH AU DÃ‰MARRAGE (Code {ret_code}) :", flush=True)
                print(f"  [LLM-LOG] {stderr_output}", flush=True)
                igor_globals.LLM_SERVER_PROCESS = None
                return False
                
            except subprocess.TimeoutExpired:
                # Si TimeoutExpired, c'est que le processus TOURNE ENCORE -> SuccÃ¨s !
                
                # On lance un thread pour lire les erreurs futures sans bloquer (ex: Out of memory plus tard)
                def monitor_stderr(proc):
                    for line in proc.stderr:
                        if "error" in line.lower() or "warning" in line.lower():
                            print(f"  [LLM-LOG] {line.strip()}", flush=True)
                
                t = threading.Thread(target=monitor_stderr, args=(igor_globals.LLM_SERVER_PROCESS,), daemon=True)
                t.start()
                
                print("  [LLM-SRV] âœ… Serveur dÃ©marrÃ© avec succÃ¨s.", flush=True)
                return True
                
        except Exception as e:
            print(f"  [LLM-SRV] Exception dÃ©marrage : {e}", flush=True)
            return False

def check_intent_category(words, actions, objects, category, focus = 0, inquiries = {}, states = {}, points_needed = 1):
    found_actions = words.intersection(actions)
    found_objects = words.intersection(objects)
    found_inquiries = set()
    found_states = set()
    if(inquiries):
        found_inquiries = words.intersection(inquiries)
    if(states):
        found_states = words.intersection(states)
    
    agent_name = set([skills.MEMORY['agent_name'].lower()])

    trust_level = 1.0

    noise_words = words - found_actions - found_objects - found_inquiries - found_states - igor_globals.STOP_WORDS - agent_name

    noise_words = {word for word in noise_words if len(word) >= 3}

    words_without_stop = words - igor_globals.STOP_WORDS - agent_name #Met la sonnerie en mode douceur > met sonnerie mode douceur

    words_diff = words_without_stop - noise_words

    #print(f"  [INTENT CATEGORY] actions: {actions}", flush=True)
    print(f"  [INTENT CATEGORY] {category}\nwords: {words}\nnoise_words: {noise_words}\nfound_actions: {len(found_actions)}\nfound_objects: {len(found_objects)}\nfound_inquiries: {len(found_inquiries)}\nfound_states: {len(found_states)}\nwords diff: {words_diff}", flush=True)

    has_action = bool(found_actions)
    has_object = bool(found_objects)
    has_inquiries = bool(found_inquiries)
    has_states = bool(found_states)
    action_count = len(found_actions)
    object_count = len(found_objects)
    inquiries_count = len(found_inquiries)
    states_count = len(found_states)
    action_points = action_count * 5
    object_points = object_count * 2
    total_points = action_points + object_points
    #inquiries_count =
    #states_count = 

    is_focused_command = len(words_diff) <= focus and (len(found_objects) + len(found_inquiries) + len(found_states)) >= points_needed

    print(f"  [INTENT POINTS] {total_points}", flush=True)
    #print(f"  [INTENT CATEGORY] has action: {has_action}", flush=True)
    #print(f"  [INTENT CATEGORY] is_focused_command: {is_focused_command}", flush=True)

    if has_action:
        total_points += inquiries_count + states_count

    #if total_points >= 7.0:
        #return category

    #if has_action:
        #if not has_object and is_focused_command:
        #    return category
        #if has_object:
        #    return category
    #return
    return total_points
    

@lru_cache(maxsize=256)
def classify_query_intent(user_input):
    """
    Classification avec prioritÃ© Ã  la comprÃ©hension sÃ©mantique (LLM) pour les phrases complexes.
    """
    current_timestamp = time.time()
    print(f"    [TIMESTAMP START] {current_timestamp}",flush=True)

    lower = user_input.lower().strip()
    cleaned = remove_accents_and_special_chars(lower)
    
    # === PHASE 0 : COMPRÃ‰HENSION D'INTENTION BRUTE (LLM FIRST) ===
    # On interroge le LLM en premier pour capturer le sens implicite (ex: "je me lÃ¨ve" = ALARME)
    # Condition : Phrase > 3 mots pour ne pas ralentir les commandes simples ("Stop", "Heure")
    if len(lower.split()) > 3:
        print(f"  [CLASSIFY] ðŸ§  Analyse sÃ©mantique profonde (LLM)...", flush=True)
        
        # Prompt spÃ©cialisÃ© pour la dÃ©duction de contexte implicite
        pre_prompt = f"""Remplis la fiche technique de la demande.
CATÃ‰GORIES : ALARM, TIME, WEATHER, MULTIMEDIA, CHAT, DEVELOPMENT, CONTROL_OS, NOTEBOOK, WEB_SEARCH, USER_KNOWN_FACTS.
COMMANDES dÃ©duites de la demande de l'utilisateur, les actions qui devront Ãªtre entreprises pour rÃ©gler la NATURE de la demande.
NATURE de la demande, mot pour mot, exclue les COMMANDES.

RÃ¨gles de dÃ©duction :
- "Ã€ quelle heure je me lÃ¨ve ?" (RÃ©veil) -> CATÃ‰GORIES: ALARM. COMMANDES: Lire les alarmes, trouver une alarme qui rÃ©pond aux critÃ¨res de sÃ©lections, rÃ©pondre Ã  l'utilisateur.
- "C'est quoi ce son ?" (Identification) -> CATÃ‰GORIES: MULTIMEDIA. COMMANDES: Ã‰couter le son systÃ¨me, analyser le son, rÃ©pondre Ã  l'utilisateur.
- "Rappelle-moi de..." (Note) -> CATÃ‰GORIES: NOTEBOOK. COMMANDES: Lire les notes, vÃ©rifier les doublons, ajouter la note au carnet de notes, rÃ©pondre Ã  l'utilisateur.
- "Il fera chaud ?" -> CATÃ‰GORIES: WEATHER. COMMANDES: Rechercher la mÃ©tÃ©o pour l'endroit prÃ©cisÃ© ou l'emplacement de gÃ©olocalisation de l'utilisateur, rÃ©pondre Ã  l'utilisateur.
- "J'ai quel Ã¢ge ?" -> CATÃ‰GORIES: USER_KNOWN_FACTS. COMMANDES: Lire les faits connus de l'utilisateur en mÃ©moire, trouver l'information pertinente, rÃ©pondre Ã  l'utilisateur.

Phrase: "{user_input}"
CATÃ‰GORIES (1 MOT MAJUSCULE),
COMMANDES (LISTE les actions),
NATURE (littÃ©ral)"""

        # Appel augmentÃ© (besoin de plus de tokens pour gÃ©nÃ©rer la fiche complÃ¨te)
        raw_response = call_llm_api(pre_prompt, n_predict=200, temperature=0.0)
        
        detected = None
        if raw_response:
            # Extraction prÃ©cise de la ligne CATÃ‰GORIES via Regex
            # Supporte "CATÃ‰GORIES" (avec accent) ou "CATEGORIES" et capture le mot suivant
            match = re.search(r"(?:CATÃ‰GORIES|CATEGORIES)\s*[:]\s*([A-Z_]+)", raw_response, re.IGNORECASE)
            if match:
                detected = match.group(1).upper().strip()
                print(f"  [CLASSIFY] ðŸ“„ Fiche extraite : {detected}\nRAW : {raw_response}", flush=True)
            
            # On accepte l'intention si ce n'est pas CHAT (pour CHAT, on laisse les filtres dÃ©cider)
            # Cela permet de forcer ALARM mÃªme si les mots clÃ©s "sonnerie" sont absents
            valid_overrides = {"ALARM", "MEDIA", "WEATHER", "TIME", "MEMORY", "PROJECT"}
            
            if detected in valid_overrides:
                print(f"  [CLASSIFY] ðŸŽ¯ Intention comprise par LLM : {detected}", flush=True)
                return detected

    ranking = dict()
    
    # === PRÃ‰-FILTRE ABSOLU : COMMANDES MULTIPLES ===
    multi_keywords = [" et ", " puis ", " ensuite ", " apres "]
    multi_count = sum(1 for multi in multi_keywords if multi in cleaned)
    
    print(f"   [MULTIACTION] Conjonctions: {multi_count}", flush=True)

    if multi_count > 0:
        # VÃ©rifier qu'il y a bien 2 verbes d'action
        verb_count = sum(1 for verb in igor_globals.MULTI_ACTIONS if verb in cleaned)
        
        print(f"   [MULTIACTION] Actions: {verb_count}", flush=True)

        if verb_count > multi_count:
            print(f"  [CLASSIFY] ðŸŽ¯ COMMANDES MULTIPLES dÃ©tectÃ©es", flush=True)
            return "CONTROL"  # CONTROL gÃ¨re le BATCH

    # === PRÃ‰-FILTRE ===
    split_words = cleaned.split()
    unique_words = set(split_words)
    apps_list = set(INSTALLED_APPS)
    
    # === PRÃ‰-FILTRE : EXIT ===
    #if (check_intent_category(unique_words, igor_globals.EXIT_ACTIONS, igor_globals.EXIT_OBJECTS, "IDENTITY", 0, set(), set(), 0)):
    #print(f"  [CLASSIFY] PRÃ‰-FILTRE: IDENTITY (EXIT) - Regex: {lower}", flush=True)
    points = check_intent_category(unique_words, igor_globals.EXIT_ACTIONS, igor_globals.EXIT_OBJECTS, "IDENTITY", 0, set(), set(), 0)
    ranking["IDENTITY"] = points
    print(f"  [CLASSIFY] PRÃ‰-FILTRE: IDENTITY (EXIT) - Regex: {lower} Points: "+str(points), flush=True)
    
    # === PRÃ‰-FILTRE : IDENTITY (BASE) ===
    points = check_intent_category(unique_words, igor_globals.BASE_ACTIONS, igor_globals.BASE_OBJECTS, "IDENTITY", 0 , igor_globals.BASE_INQUIRIES)
    if ranking["IDENTITY"] < points:
        ranking["IDENTITY"] = points
    print(f"  [CLASSIFY] PRÃ‰-FILTRE: IDENTITY (BASE) - Regex: {lower} Points: "+str(points), flush=True)
    
    # === PRÃ‰-FILTRE : SET FAVORITE ===
    points = check_intent_category(unique_words, igor_globals.SETFAVORITE_ACTIONS, igor_globals.SETFAVORITE_OBJECTS, "CONTROL", 1)
    ranking["CONTROL"] = points
    print(f"  [CLASSIFY] PRÃ‰-FILTRE: CONTROL (SET_FAVORITE) - Regex: {lower} Points: "+str(points), flush=True)

    # === PRÃ‰-FILTRE : MEDIA (VOLUME) ===
    points = check_intent_category(unique_words, igor_globals.VOLUME_ACTIONS, igor_globals.VOLUME_OBJECTS, "MEDIA")
    ranking["MEDIA"] = points
    print(f"  [CLASSIFY] â›” PRÃ‰-FILTRE: MEDIA (VOLUME) - Regex: {lower} Points: "+str(points), flush=True)
        
    # === PRÃ‰-FILTRE : SET_MUTE ===
    points = check_intent_category(unique_words, igor_globals.MUTE_ACTIONS, igor_globals.MUTE_OBJECTS, "MEDIA")
    if ranking["MEDIA"] < points:
        ranking["MEDIA"] = points
    print(f"  [CLASSIFY] â›” PRÃ‰-FILTRE: MEDIA (SET_MUTE) - Regex: {lower} Points: "+str(points), flush=True)
        
    # === PRÃ‰-FILTRE : MEDIA ===
    points = check_intent_category(unique_words, igor_globals.LISTEN_ACTIONS, igor_globals.LISTEN_OBJECTS, "MEDIA", 0)
    if ranking["MEDIA"] < points:
        ranking["MEDIA"] = points
    print(f"  [CLASSIFY] PRÃ‰-FILTRE: MEDIA (LISTEN_SYSTEM)- Regex: {lower} Points: "+str(points), flush=True)
    
    # === PRÃ‰-FILTRE : MEDIA ===
    points = check_intent_category(unique_words, igor_globals.MEDIA_ACTIONS, igor_globals.MEDIA_OBJECTS, "MEDIA", 1)
    if ranking["MEDIA"] < points:
        ranking["MEDIA"] = points
    print(f"  [CLASSIFY] PRÃ‰-FILTRE: MEDIA - Regex: {lower} Points: "+str(points), flush=True)
    
    # === PRÃ‰-FILTRE : SYSTEM (FIND) ===
    points = check_intent_category(unique_words, igor_globals.FIND_ACTIONS, igor_globals.FIND_OBJECTS, "SYSTEM", 1)
    ranking["SYSTEM"] = points
    print(f"  [CLASSIFY] PRÃ‰-FILTRE: SYSTEM (FIND) - Regex: {lower} Points: "+str(points), flush=True)
    
    # === PRÃ‰-FILTRE : MEMORY ===
    points = check_intent_category(unique_words, igor_globals.NOTES_ACTIONS, igor_globals.NOTES_OBJECTS, "MEMORY")
    ranking["MEMORY"] = points
    print(f"  [CLASSIFY] PRÃ‰-FILTRE: MEMORY (NOTES)- Regex: {lower} Points: "+str(points), flush=True)
    
    # === PRÃ‰-FILTRE : LAUNCH (app) ===   
    open_objects = igor_globals.OPEN_OBJECTS | apps_list
    points = check_intent_category(unique_words, igor_globals.OPEN_ACTIONS, open_objects, "LAUNCH", 1)
    ranking["LAUNCH"] = points
    print(f"  [CLASSIFY] PRÃ‰-FILTRE: LAUNCH (APP)- Regex: {lower} Points: "+str(points), flush=True)
        
    # === PRÃ‰-FILTRE : LAUNCH (web) ===   
    points = check_intent_category(unique_words, igor_globals.WEB_ACTIONS, igor_globals.WEB_OBJECTS, "LAUNCH")
    if ranking["LAUNCH"] < points:
        ranking["LAUNCH"] = points
    print(f"  [CLASSIFY] PRÃ‰-FILTRE: LAUNCH (WEB)- Regex: {lower} Points: "+str(points), flush=True)
        
    # === PRÃ‰-FILTRE : SHELL ===
    points = check_intent_category(unique_words, igor_globals.SHELL_ACTIONS, igor_globals.SHELL_OBJECTS, "SYSTEM", 1)
    if ranking["SYSTEM"] < points:
        ranking["SYSTEM"] = points
    print(f"  [CLASSIFY] PRÃ‰-FILTRE: SYSTEM (SHELL)- Regex: {lower} Points: "+str(points), flush=True)
        
    # === PRÃ‰-FILTRE : CONTROL (FULLSCREEN) ===
    fullscreen_objects = igor_globals.FULLSCREEN_OBJECTS | apps_list
    points = check_intent_category(unique_words, igor_globals.FULLSCREEN_ACTIONS, fullscreen_objects, "CONTROL", 0, set(), igor_globals.FULLSCREEN_STATES)
    if ranking["CONTROL"] < points:
        ranking["CONTROL"] = points
    print(f"  [CLASSIFY] PRÃ‰-FILTRE: CONTROL (FULLSCREEN)- Regex: {lower} Points: "+str(points), flush=True)
        
    # === PRÃ‰-FILTRE : CONTROL (CLOSE WINDOW)===
    close_object = igor_globals.CLOSE_OBJECTS | apps_list
    points = check_intent_category(unique_words, igor_globals.CLOSE_ACTIONS, close_object, "CONTROL", 0)
    if ranking["CONTROL"] < points:
        ranking["CONTROL"] = points
    print(f"  [CLASSIFY] PRÃ‰-FILTRE: CONTROL (CLOSE WINDOW)- Regex: {lower} Points: "+str(points), flush=True)
        
    # === PRÃ‰-FILTRE : CONTROL ===
    points = check_intent_category(unique_words, igor_globals.CONTROL_ACTIONS, igor_globals.CONTROL_OBJECTS, "CONTROL", 0)
    if ranking["CONTROL"] < points:
        ranking["CONTROL"] = points
    print(f"  [CLASSIFY] PRÃ‰-FILTRE: CONTROL - Regex: {lower} Points: "+str(points), flush=True)
        
    # === PRÃ‰-FILTRE : CONTROL (WINDOW) ===
    points = check_intent_category(unique_words, igor_globals.WINDOWSTATS_ACTIONS, igor_globals.WINDOWSTATS_OBJECTS,
                               "CONTROL", 1, igor_globals.WINDOWSTATS_INQUIRIES, igor_globals.WINDOWSTATS_STATES)
    if ranking["CONTROL"] < points:
        ranking["CONTROL"] = points
    print(f"  [CLASSIFY] PRÃ‰-FILTRE: CONTROL (WINDOW)- Regex: {lower} Points: "+str(points), flush=True)
        
    # === PRÃ‰-FILTRE : CONTROL (FOCUS) ===
    focus_objects = igor_globals.FOCUS_OBJECTS | apps_list
    points = check_intent_category(unique_words, igor_globals.FOCUS_ACTIONS, focus_objects, "CONTROL", 1)
    if ranking["CONTROL"] < points:
        ranking["CONTROL"] = points
    print(f"  [CLASSIFY] PRÃ‰-FILTRE: CONTROL (FOCUS)- Regex: {lower} Points: "+str(points), flush=True)
        
    # === PRÃ‰-FILTRE : VISION ===
    points = check_intent_category(unique_words, igor_globals.VISION_ACTIONS, igor_globals.VISION_OBJECTS, "VISION")
    ranking["VISION"] = points
    print(f"  [CLASSIFY] PRÃ‰-FILTRE: VISION - Regex: {lower} Points: "+str(points), flush=True)
    
    # === PRÃ‰-FILTRE : SHORTCUT ===
    points = check_intent_category(unique_words, igor_globals.SHORTCUTLIST_ACTIONS, igor_globals.SHORTCUTLIST_OBJECTS, "SHORTCUT", 0)
    ranking["SHORTCUT"] = points
    print(f"  [CLASSIFY] PRÃ‰-FILTRE: SHORTCUT (SHORTCUT_LIST)- Regex: {lower} Points: "+str(points), flush=True)
    
    # === PRÃ‰-FILTRE : SHORTCUT ===
    points = check_intent_category(unique_words, igor_globals.SHORTCUT_ACTIONS, igor_globals.SHORTCUT_OBJECTS, "SHORTCUT", 2)
    if ranking["SHORTCUT"] < points:
        ranking["SHORTCUT"] = points
    print(f"  [CLASSIFY] PRÃ‰-FILTRE: SHORTCUT - Regex: {lower} Points: "+str(points), flush=True)
    
    # === PRÃ‰-FILTRE : MEMORY ===
    points = check_intent_category(unique_words, igor_globals.READMEM_ACTIONS, igor_globals.READMEM_OBJECTS, "MEMORY")
    if ranking["MEMORY"] < points:
        ranking["MEMORY"] = points
    print(f"  [CLASSIFY] PRÃ‰-FILTRE: MEMORY (READ_MEM)- Regex: {lower} Points: "+str(points), flush=True)
    
    # === PRÃ‰-FILTRE : SEARCH (TIME) ===
    points = check_intent_category(unique_words, igor_globals.TIME_ACTIONS, igor_globals.TIME_OBJECTS, "SEARCH", 1, igor_globals.TIME_INQUIRIES)
    ranking["SEARCH"] = points
    print(f"  [CLASSIFY] PRÃ‰-FILTRE: SEARCH (TIME)- Regex: {lower} Points: "+str(points), flush=True)
    
    # === PRÃ‰-FILTRE : SEARCH (METEO) ===
    points = check_intent_category(unique_words, igor_globals.METEO_ACTIONS, igor_globals.METEO_OBJECTS, "SEARCH", 1, igor_globals.METEO_INQUIRIES)
    if ranking["SEARCH"] < points:
        ranking["SEARCH"] = points
    print(f"  [CLASSIFY] PRÃ‰-FILTRE: SEARCH (METEO)- Regex: {lower} Points: "+str(points), flush=True)
    
    # === PRÃ‰-FILTRE : KNOWLEDGE ===
    points = check_intent_category(unique_words, igor_globals.LEARN_ACTIONS, igor_globals.LEARN_OBJECTS, "KNOWLEDGE", 3)
    ranking["KNOWLEDGE"] = points
    print(f"  [CLASSIFY] PRÃ‰-FILTRE: KNOWLEDGE (LEARN)- Regex: {lower} Points: "+str(points), flush=True)
    
    # === PRÃ‰-FILTRE : SEARCH ===
    points = check_intent_category(unique_words, igor_globals.SEARCH_ACTIONS, igor_globals.SEARCH_OBJECTS, "SEARCH", 4)
    if ranking["SEARCH"] < points:
        ranking["SEARCH"] = points
    print(f"  [CLASSIFY] PRÃ‰-FILTRE: SEARCH - Regex: {lower} Points: "+str(points), flush=True)
    
    # === PRÃ‰-FILTRE : CONTROL OPEN_FILE ===
    points = check_intent_category(unique_words, igor_globals.OPEN_ACTIONS, igor_globals.OPEN_OBJECTS, "CONTROL", 2)
    if ranking["CONTROL"] < points:
        ranking["CONTROL"] = points
    print(f"  [CLASSIFY] PRÃ‰-FILTRE: CONTROL (OPEN_FILE) - Regex: {lower} Points: "+str(points), flush=True)
    
    # === PRÃ‰-FILTRE : MEMORY ===
    points = check_intent_category(unique_words, igor_globals.MEMORY_ACTIONS, igor_globals.MEMORY_OBJECTS, "MEMORY", 10)
    if ranking["MEMORY"] < points:
        ranking["MEMORY"] = points
    print(f"  [CLASSIFY] PRÃ‰-FILTRE: MEMORY - Regex: {lower} Points: "+str(points), flush=True)
    
    # === PRÃ‰-FILTRE : LAUNCH ===
    launch_keywords = ["ouvre", "lance", "demarre", "va sur", "open", "start", "affiche", 
                       "mets", "met", "joue", "regarde", "montre"]
    video_keywords = ["video", "youtube", "clip", "film"]
    
    has_launch = any(k in cleaned for k in launch_keywords)
    has_video = any(k in cleaned for k in video_keywords)
    
    # VÃ©rification anti-conflit (Calculs ou Commandes Shell)
    is_calculation = any(calc in cleaned for calc in ["calcul de", "resultat de", "combien"])
    is_shell_cmd = "commande" in cleaned or "shell" in cleaned
    
    if has_launch:
        if not is_calculation and not is_shell_cmd:
            print(f"  [CLASSIFY] PRÃ‰-FILTRE: LAUNCH", flush=True)
            if ranking["LAUNCH"] < 7:
                ranking["LAUNCH"] = 7
    
    if has_video:
        print(f"  [CLASSIFY] PRÃ‰-FILTRE: LAUNCH (VIDEO)", flush=True)
        if ranking["LAUNCH"] < 7:
            ranking["LAUNCH"] = 7
    
    # === PRÃ‰-FILTRE : MATH (calculs) ===
    has_operators = any(op in user_input for op in ['+', '-', '*', '/', '=', '^'])
    has_calc_words = any(w in cleaned for w in ["calcule", "combien fait", "rÃ©sultat de"])
    is_app_launch = any(f"{launch} " in cleaned for launch in ["lance", "ouvre", "dÃ©marre"])
    
    if (has_operators or has_calc_words) and not is_app_launch:
        print(f"  [CLASSIFY] PRÃ‰-FILTRE: KNOWLEDGE (MATH)", flush=True)
        if ranking["KNOWLEDGE"] < 7:
            ranking["KNOWLEDGE"] = 7
    
    current_timestamp = time.time() - current_timestamp
    print(f"    [TIMESTAMP END] {current_timestamp*0.0001}ms",flush=True)

    # === PRÃ‰-FILTRE : PROJECT ===
    if any(k in cleaned for k in ["projet", "code", "fichier", "todo", "sauve"]):
        print(f"  [CLASSIFY] PRÃ‰-FILTRE: PROJECT", flush=True)
        ranking["PROJECT"] = 7
    
    # === PRÃ‰-FILTRE : IDENTITY (noms) ===
    # On rend la dÃ©tection plus agressive pour capturer les affirmations "Tu es..."
    identity_keywords = ["appelle", "nom", "prÃ©nom", "suis", "es tu", "tu es", "t'es", "qui es", "qui suis"]
    if any(w in cleaned for w in identity_keywords):
        # On vÃ©rifie qu'on parle bien de personnes (je/tu/mon/ton)
        if any(pron in cleaned for pron in ["je", "j'", "mon", "ma", "mes", "tu", "te", "ton", "ta", "tes", "moi", "toi", "t'", "m'"]):
            print(f"  [CLASSIFY] PRÃ‰-FILTRE: IDENTITY", flush=True)
            if ranking["IDENTITY"] < 7:
                ranking["IDENTITY"] = 7

    # === PRÃ‰-FILTRE : ALARM ===
    # AJOUT des versions sans accents (reveil, reveille)
    alarm_keywords = ["alarme", "reveil", "reveille", "sonnerie", "debout"]
    if any(k in cleaned for k in alarm_keywords):
        # Si on dÃ©tecte une notion de temps (chiffres, "dans", "Ã ", "h", "min")
        # ET qu'on ne parle pas de configuration ("change", "style", "son")
        time_triggers = ["dans", "Ã ", "pour", "minutes", "heures", "h", "min", "sec"]
        has_time = any(t in cleaned for t in time_triggers) or any(char.isdigit() for char in cleaned)
        
        is_config = any(s in cleaned for s in ["change", "rÃ¨gle", "dÃ©finit", "style", "type", "bruit", "son"])
        
        if has_time and not is_config:
            # FIX : On retourne la CATEGORIE (str) pour que brain_query charge les outils ALARM.
            # L'extraction des arguments sera faite par l'IA ou l'heuristique.
            print(f"  [CLASSIFY] PRÃ‰-FILTRE: ALARM (Intent Detect)", flush=True)
            return "ALARM"

        print(f"  [CLASSIFY] PRÃ‰-FILTRE: ALARM (Intent)", flush=True)
        return "ALARM"
        
    sorted_ranking = dict(sorted(ranking.items(), key=lambda item: item[1], reverse=True))

    print(f"    [DEBUG RANKING] {sorted_ranking}",flush=True)

    value = list(sorted_ranking.values())[0]
    key = list(sorted_ranking.keys())[0]
    if value >= 7:
        print(f"CATEGORIE: {key} VALEUR: {value}",flush=True)
        return key

    # === APPEL IA (Seulement si aucun prÃ©-filtre) ===
    prompt = f"""Classifie en 1 MOT parmi: IDENTITY MEDIA SHORTCUT VISION PROJECT ALARM SEARCH KNOWLEDGE LAUNCH CONTROL MEMORY CHAT

Phrase: "{user_input}"
RÃ©ponse (1 mot uniquement):"""
    
    #prompt = f"""RÃ©pond Ã  QUOI? 

#Phrase: "{user_input}"
#RÃ©ponse (1 mot uniquement):"""

    # Appel unifiÃ©
    raw_intent = call_llm_api(prompt, n_predict=10, temperature=0.0)
    
    if not raw_intent:
         print(f"  [CLASSIFY] API Error ou Vide â†’ CHAT", flush=True)
         return "CHAT"
    
    raw_intent = raw_intent.strip().upper()
        
    print(f" [RAW INTENT] {raw_intent}",flush=True)

    if not raw_intent:
        print(f"  [CLASSIFY] RÃ©ponse vide â†’ CHAT", flush=True)
        return "CHAT"
    
    intent = re.sub(r'[^A-Z]', '', raw_intent)
    
    valid_intents = {
        "IDENTITY", "MEDIA", "SHORTCUT", "VISION", "PROJECT", 
        "ALARM", "SEARCH", "KNOWLEDGE", "LAUNCH", "CONTROL", 
        "MEMORY", "CHAT"
    }
    
    if intent not in valid_intents:
        print(f"  [CLASSIFY] Intent IA inconnu '{intent}' (raw:'{raw_intent}') â†’ CHAT", flush=True)
        return "CHAT"
    
    print(f"  [CLASSIFY] Intent IA: {intent}", flush=True)
    return intent

def remove_accents_and_special_chars(input_str):
    # Normalize to NFD (Normalization Form D) - decomposes accents into base characters and combining marks
    nfkd_form = unicodedata.normalize('NFD', input_str)
    
    # Filter out combining characters (Unicode category 'Mn' is for Mark, Nonspacing)
    # and keep only printable ASCII characters (optional, to remove other special symbols)
    cleaned_chars = [c for c in nfkd_form if not unicodedata.combining(c) and c in string.printable]
    
    # Join the characters back into a string
    cleaned_str = ''.join(cleaned_chars)
    
    # Optional: use regex to keep only alphanumeric characters and spaces
    import re
    cleaned_str = re.sub(r'[^a-zA-Z0-9\s]', '', cleaned_str)
    
    return cleaned_str

def extract_json_from_response(raw_text):
    """
    Extrait le JSON d'une rÃ©ponse LLM mÃªme si elle contient du texte parasite.
    Essaie plusieurs stratÃ©gies dans l'ordre.
    VERSION CORRIGÃ‰E : Prend le PREMIER objet JSON valide trouvÃ©.
    """
    import re

    # --- SPÃ‰CIAL DEEPSEEK R1 / REASONING ---
    # Suppression radicale des blocs de pensÃ©e <think>...</think>
    # Le flag re.DOTALL permet au . de matcher aussi les retours Ã  la ligne
    if "<think>" in raw_text:
        print(f"  [BRAIN] ðŸ§  Nettoyage de la pensÃ©e (DeepSeek-R1 detected)", flush=True)
        raw_text = re.sub(r'<think>.*?</think>', '', raw_text, flags=re.DOTALL).strip()
    # ---------------------------------------
    
    # ðŸ†• STRATÃ‰GIE 0 : Extraction ultra-prÃ©coce (avant mÃªme les regex)
    # Si le texte commence directement par { ou [, on essaie de parser jusqu'au premier objet/array complet
    if raw_text.strip().startswith('{'):
        # On cherche l'accolade fermante qui correspond
        brace_count = 0
        for i, char in enumerate(raw_text):
            if char == '{': brace_count += 1
            elif char == '}': brace_count -= 1
            
            if brace_count == 0 and i > 0:
                # On a trouvÃ© la fin du premier objet
                candidate = raw_text[:i+1]
                try:
                    parsed = json.loads(candidate)
                    # âœ… VALIDATION : Doit avoir "tool"
                    if isinstance(parsed, dict) and 'tool' in parsed:
                        print(f"  [JSON-EXTRACT] âœ… StratÃ©gie 0 (Early-cut) : {candidate[:80]}...", flush=True)
                        return parsed, None
                except:
                    pass
                break
    
    elif raw_text.strip().startswith('['):
        # MÃªme logique pour les tableaux
        bracket_count = 0
        for i, char in enumerate(raw_text):
            if char == '[': bracket_count += 1
            elif char == ']': bracket_count -= 1
            
            if bracket_count == 0 and i > 0:
                candidate = raw_text[:i+1]
                try:
                    parsed = json.loads(candidate)
                    # âœ… VALIDATION : Doit Ãªtre une liste de dicts avec "tool"
                    if isinstance(parsed, list) and all(isinstance(x, dict) and 'tool' in x for x in parsed):
                        print(f"  [JSON-EXTRACT] âœ… StratÃ©gie 0 (Early-cut) : {candidate[:80]}...", flush=True)
                        return parsed, None
                except:
                    pass
                break
    
    # StratÃ©gie 1 : Regex pour trouver {...} ou [...]
    json_patterns = [
        r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}',  # Objet JSON
        r'\[[^\[\]]*(?:\[[^\[\]]*\][^\[\]]*)*\]'  # Liste JSON
    ]
    
    for pattern in json_patterns:
        matches = re.findall(pattern, raw_text, re.DOTALL)
        if matches:
            # ðŸ†• MODIFICATION : Au lieu de prendre le plus long, on essaie TOUS les matches
            # et on prend le PREMIER qui est valide et contient "tool"
            for candidate in matches:
                try:
                    parsed = json.loads(candidate)
                    
                    # Validation : Doit avoir "tool" (dict) ou Ãªtre une liste de dicts avec "tool"
                    if isinstance(parsed, dict) and 'tool' in parsed:
                        print(f"  [JSON-EXTRACT] âœ… StratÃ©gie 1 (Regex) : {candidate[:80]}...", flush=True)
                        return parsed, None
                    elif isinstance(parsed, list) and all(isinstance(x, dict) and 'tool' in x for x in parsed):
                        print(f"  [JSON-EXTRACT] âœ… StratÃ©gie 1 (Regex-List) : {candidate[:80]}...", flush=True)
                        return parsed, None
                except:
                    continue
    
    # StratÃ©gie 2 : Cherche entre marqueurs ```json ou ```
    code_block = re.search(r'```(?:json)?\s*(\{.*?\}|\[.*?\])\s*```', raw_text, re.DOTALL)
    if code_block:
        try:
            parsed = json.loads(code_block.group(1))
            if isinstance(parsed, dict) and 'tool' in parsed:
                print(f"  [JSON-EXTRACT] âœ… StratÃ©gie 2 (Code block)", flush=True)
                return parsed, None
            elif isinstance(parsed, list):
                print(f"  [JSON-EXTRACT] âœ… StratÃ©gie 2 (Code block list)", flush=True)
                return parsed, None
        except:
            pass
    
    # StratÃ©gie 3 : Split sur newlines et garde la ligne la plus longue qui parse
    for line in raw_text.split('\n'):
        line = line.strip()
        if (line.startswith('{') or line.startswith('[')) and len(line) > 10:
            try:
                parsed = json.loads(line)
                if isinstance(parsed, dict) and 'tool' in parsed:
                    print(f"  [JSON-EXTRACT] âœ… StratÃ©gie 3 (Line) : {line[:80]}...", flush=True)
                    return parsed, None
                elif isinstance(parsed, list):
                    print(f"  [JSON-EXTRACT] âœ… StratÃ©gie 3 (Line list)", flush=True)
                    return parsed, None
            except:
                continue
    
    # ðŸ†• StratÃ©gie 4 : Nettoyage de la flÃ¨che (â†’) et tout ce qui suit
    if 'â†’' in raw_text:
        clean_text = raw_text.split('â†’')[0].strip()
        print(f"  [JSON-EXTRACT] ðŸ§¹ Nettoyage flÃ¨che dÃ©tectÃ©. Avant: {len(raw_text)} chars, AprÃ¨s: {len(clean_text)} chars", flush=True)
        try:
            parsed = json.loads(clean_text)
            if isinstance(parsed, dict) and 'tool' in parsed:
                print(f"  [JSON-EXTRACT] âœ… StratÃ©gie 4 (Arrow-clean)", flush=True)
                return parsed, None
        except:
            pass
    
    return None, f"Aucun JSON valide trouvÃ© dans : {raw_text[:200]}"

def fallback_intent_detection(user_input):
    """
    Si le parsing JSON Ã©choue totalement, on devine l'intention par mots-clÃ©s.
    Version simplifiÃ©e mais robuste.
    """
    lower = user_input.lower().strip()
    
    # Dictionnaire de patterns simples
    fallback_map = {
        # Format: (mots_clÃ©s, tool, args_extractor)
        ("quelle heure", "heure", "time"): ("TIME", ""),
        ("mÃ©tÃ©o", "temps qu'il fait"): ("WEATHER", ""),
        ("cherche", "recherche", "google"): ("SEARCH", user_input),
        ("ouvre", "lance", "dÃ©marre"): ("LAUNCH", user_input),
        ("calcul", "combien", "rÃ©sultat"): ("MATH", user_input),
        ("note", "retiens"): ("NOTE", user_input),
        ("alarme", "rÃ©veille"): ("ALARM", user_input),
    }
    
    for keywords, action in fallback_map.items():
        if any(kw in lower for kw in keywords):
            tool, args = action if isinstance(action, tuple) else (action, user_input)
            print(f"  [FALLBACK] DÃ©tection par mots-clÃ©s : {tool}", flush=True)
            return tool, args
    
    # Si vraiment rien ne matche
    return "CHAT", f"Je n'ai pas compris '{user_input}'. Peux-tu reformuler avec d'autres mots ?"

def force_batch_if_needed(user_input, parsed_result):
    """
    VÃ©rifie si la rÃ©ponse de l'IA devrait Ãªtre un BATCH mais ne l'est pas.
    Corrige automatiquement si besoin avec hÃ©ritage du verbe prÃ©cÃ©dent.
    VERSION CORRIGÃ‰E : Nettoyage "propre" via Regex (ne casse pas "calcu-la-trice").
    """
    lower = user_input.lower()
    
    # DÃ©tection des mots de liaison
    multi_keywords = [" et ", " puis ", " ensuite ", " aprÃ¨s "]
    has_multi = any(kw in lower for kw in multi_keywords)
    
    if not has_multi:
        return parsed_result
    
    # Si c'est dÃ©jÃ  un tableau, OK
    if isinstance(parsed_result, list):
        return parsed_result
    
    # Si c'est un dict simple, on tente la rÃ©paration
    if isinstance(parsed_result, dict):
        # Liste des verbes d'action
        action_map = {
            "ferme": "CLOSE_WINDOW", "Ã©teins": "CLOSE_WINDOW", "arrÃªte": "CLOSE_WINDOW",
            "ouvre": "LAUNCH", "lance": "LAUNCH", "dÃ©marre": "LAUNCH", "mets": "LAUNCH", "met": "LAUNCH"
        }
        
        # On vÃ©rifie si au moins un verbe est prÃ©sent
        if any(v in lower for v in action_map):
            print(f"  [BATCH-FIX] âš ï¸ Tentative de dÃ©coupage intelligent...", flush=True)
            
            # DÃ©coupage par "et", "puis", etc.
            parts = re.split(r'\s+(?:et|puis|ensuite|aprÃ¨s)\s+', lower)
            
            if len(parts) >= 2:
                actions = []
                last_tool = None 
                
                for part in parts:
                    part = part.strip()
                    current_tool = None
                    
                    # 1. On cherche un verbe explicite dans ce segment
                    found_verb = False
                    for verb, tool in action_map.items():
                        if verb in part:
                            current_tool = tool
                            last_tool = tool 
                            # NETTOYAGE SÃ‰CURISÃ‰ DU VERBE (1Ã¨re occurrence seulement)
                            part = part.replace(verb, "", 1).strip()
                            found_verb = True
                            break
                    
                    # 2. Si pas de verbe, on utilise le dernier outil connu (HÃ©ritage)
                    if not found_verb and last_tool:
                        current_tool = last_tool

                    # 3. NETTOYAGE DES DETERMINANTS (Regex pour mots entiers uniquement)
                    # \b = limite de mot. Ã‰vite de supprimer "la" dans "calculatrice"
                    if current_tool:
                        part = re.sub(r'\b(le|la|les|un|une|du|de)\b', '', part).strip()
                        part = part.replace("l'", "").replace("d'", "").strip()
                        
                        # Si on a trouvÃ© un outil et qu'il reste du texte
                        if len(part) > 1:
                            actions.append({"tool": current_tool, "args": part})
                
                # Si on a rÃ©ussi Ã  extraire au moins 2 actions valides
                if len(actions) >= 2:
                    print(f"  [BATCH-FIX] âœ… RÃ©paration rÃ©ussie (Regex) : {actions}", flush=True)
                    return actions
    
    return parsed_result

def brain_query(user_input):
    print(f"\n{'='*20} [DEBUG] ENTRÃ‰E CHAT {'='*20}\n>>> {user_input}\n{'='*55}", flush=True)

    """
    Cerveau de l'agent - Version 2.2 (Anti-Hallucination R1 & Json Fix).
    """
    # === Ã‰TAPE 0 : PRÃ‰-FILTRE HEURISTIQUE (ACTIVÃ‰) ===
    #quick_result = quick_heuristic_check(user_input)
    #if quick_result:
        #print(f"  [BRAIN] âš¡ Heuristique appliquÃ©e : {quick_result}", flush=True)
        # On formate pour simuler une rÃ©ponse IA si c'est un tuple (TOOL, ARGS)
        #if isinstance(quick_result, tuple):
            #return quick_result[0], quick_result[1]
        #return quick_result
    
    # === Ã‰TAPE 1 : CLASSIFICATION ===
    intent = classify_query_intent(user_input)
    
    # === Ã‰TAPE 2 : CONSTRUCTION CONTEXTE MINIMAL ===
    current_name = skills.MEMORY['agent_name']
    user_name = skills.MEMORY['user_name']
    current_proj = skills.MEMORY.get('current_project', 'Aucun')
    
    context_parts = []
    context_parts.append(f"Agent: {current_name}, User: {user_name}")
    
    # Historique (seulement pour CHAT)
    if intent == "CHAT":
        last_msgs = igor_globals.CHAT_HISTORY[-2:] if igor_globals.CHAT_HISTORY else []
        if last_msgs:
            context_parts.append(f"Historique: {' | '.join(last_msgs)}")
    
    # Contexte spÃ©cifique selon l'intent
    local_files_str = ""
    facts_str = ""
    
    if intent == "PROJECT":
        context_parts.append(f"Projet actif: {current_proj}")
    
    if intent == "KNOWLEDGE":
        try:
            files = glob.glob(os.path.join(skills.KNOWLEDGE_DIR, "*.txt"))
            local_files = [os.path.basename(f).replace(".txt", "").replace("_", " ") for f in files[:8]]
            local_files_str = ", ".join(local_files) if local_files else "Aucun"
        except:
            local_files_str = "Aucun"
    
    if intent in ["MEMORY", "CHAT"]:
        facts = skills.MEMORY.get('facts', [])
        if facts:
            facts_str = "; ".join(facts[:3])
    
    context_str = "\n".join(context_parts)
    
    # === Ã‰TAPE 3 : RÃ‰CUPÃ‰RATION MICRO-PROMPT ===
    micro_prompt_template = igor_globals.MICRO_PROMPTS.get(intent, igor_globals.MICRO_PROMPTS["CHAT"])
    
    # === INJECTION VARIABLES DYNAMIQUES ===
    format_vars = {
        'current_proj': current_proj,
        'local_files': local_files_str if local_files_str else "Aucun",
        'facts': facts_str if facts_str else "Aucun"
    }
    
    micro_prompt = micro_prompt_template
    for key, value in format_vars.items():
        placeholder = "{" + key + "}"
        if placeholder in micro_prompt:
            micro_prompt = micro_prompt.replace(placeholder, str(value))
    
    # === Ã‰TAPE 4 : SÃ‰LECTION OUTILS (Charge SEULEMENT le groupe concernÃ©) ===
    relevant_groups = igor_globals.INTENT_TOOL_GROUPS.get(intent, ["BASE"])
    
    print(f"\n{'='*20} [DEBUG] RAISON MICROPROMPT {'='*16}\nINTENTION DÃ‰TECTÃ‰E : {intent}\nGROUPES ASSOCIÃ‰S   : {relevant_groups}\nRAISON             : L'intention '{intent}' force l'inclusion des outils {relevant_groups} et du guide spÃ©cifique '{intent}'.\n{'='*58}", flush=True)

    tools_list = []
    
    for group_name in relevant_groups:
        if group_name in igor_globals.TOOLS_GROUPS:
            tools_list.extend(igor_globals.TOOLS_GROUPS[group_name])
    
    # DÃ©doublonnage
    tools_list = list(set(tools_list))
    tools_str = "\n".join([f"- {t}" for t in tools_list])
    
    # === Ã‰TAPE 5 : PROMPT FINAL (DYNAMIQUE) ===
    
    # --- MODIFICATION DEEPSEEK-R1 ---
    current_model = skills.MEMORY.get('llm_model_name', '').lower()
    is_r1 = "r1" in current_model or "deepseek" in current_model or "reason" in current_model

    if is_r1:
        # RÃ¨gles R1 : On autorise le <think> mais on blinde la sortie et les outils
        # On ajoute une instruction explicite pour forcer l'usage des outils existants
        rules_block = """RÃˆGLES DE GÃ‰NÃ‰RATION:
1. Analyse la demande. Tu PEUX rÃ©flÃ©chir dans un bloc <think>...</think>.
2. Ta rÃ©ponse FINALE (aprÃ¨s la pensÃ©e) doit Ãªtre UNIQUEMENT le bloc JSON.
3. INTERDICTION D'INVENTER DES OUTILS. Utilise SEULEMENT la liste fournie.
   - Pour fermer un programme/app : utilise "CLOSE_WINDOW".
   - Pour lancer : utilise "LAUNCH".
4. Format: {"tool": "NOM", "args": "valeur"}
5. Pas de markdown autour du JSON final."""
    else:
        # RÃ¨gles strictes pour Llama.cpp/Mistral
        rules_block = """RÃˆGLES ABSOLUES:
1. UNE action : {"tool": "NOM", "args": "valeur"}
2. PLUSIEURS actions (si "et", "puis") : [{"tool":...}, {"tool":...}]
3. PAS de texte avant/aprÃ¨s le JSON
4. PAS de markdown (```json)
5. Si doute â†’ utilise CHAT"""
    # --------------------------------

    prompt = f"""Tu es {current_name} (l'agent IA). Tu DOIS rÃ©pondre UNIQUEMENT avec du JSON valide.

CONTEXTE:
{context_str}

GUIDE SPÃ‰CIFIQUE:
{micro_prompt}

OUTILS:
{tools_str}

{rules_block}

EXEMPLES:
User: "Quelle heure ?" â†’ {{"tool": "TIME", "args": ""}}
User: "Ferme Firefox" â†’ {{"tool": "CLOSE_WINDOW", "args": "Firefox"}}
User: "Ouvre la calculette" â†’ {{"tool": "LAUNCH", "args": "calculatrice"}}

User: "{user_input}"
JSON:"""
    
    # === Ã‰TAPE 6 : APPEL API ===
    grammar_json = "root ::= object | list\nobject ::= \"{\" pair (\",\" pair)* \"}\"\npair ::= string \":\" value\nstring ::= '\"' [^\"]* '\"'\nvalue ::= string | number | object | list\nlist ::= \"[\" (object (\",\" object)*)? \"]\"\nnumber ::= [0-9]+"
    
    # Appel via la nouvelle fonction unifiÃ©e
    raw = call_llm_api(prompt, n_predict=300, temperature=0.1, grammar=grammar_json)

    try:
        if not raw:
             return fallback_intent_detection(user_input)
        
        # Log tronquÃ© pour Ã©viter le spam <think>
        print(f"\n{'='*20} [DEBUG] SORTIE AGENT (BRUT) {'='*15}\n{raw[:500]}...", flush=True)

        parsed, error = extract_json_from_response(raw)
        
        # --- NOUVEAU BLOC : RÃ‰PARATION DES HALLUCINATIONS JSON DE R1 (RenforcÃ©) ---
        if parsed:
            # CAS 1 : Le modÃ¨le renvoie une liste simple [TOOL, ARGS] au lieu d'un dict
            # Ex: ["CLOSE_WINDOW", "Firefox"]
            if isinstance(parsed, list) and len(parsed) > 0 and isinstance(parsed[0], str):
                print(f"  [BRAIN] ðŸ”§ Correction R1 (Format Liste dÃ©tectÃ©)", flush=True)
                tool = parsed[0]
                args = str(parsed[1]) if len(parsed) > 1 else ""
                
                # NETTOYAGE RENFORCÃ‰ DES ARGS : Si args ressemble Ã  "args: 'Firefox'"
                # R1 a tendance Ã  mettre le nom de la clÃ© dans la valeur quand il fait des listes
                if "args" in args:
                    # EnlÃ¨ve "args", ":", "=" et les quotes
                    args = re.sub(r"args[:=]*\s*", "", args, flags=re.IGNORECASE).strip().strip("'").strip('"')
                
                parsed = {"tool": tool, "args": args}

            # CAS 2 : Le champ 'tool' contient une liste (Hallucination imbriquÃ©e)
            # Ex: {"tool": ["CLOSE_WINDOW", "Firefox"]}
            elif isinstance(parsed, dict) and isinstance(parsed.get('tool'), list):
                print(f"  [BRAIN] ðŸ”§ Correction R1 (Tool est une liste)", flush=True)
                raw_list = parsed['tool']
                if len(raw_list) > 0:
                    parsed['tool'] = raw_list[0]
                    if not parsed.get('args') and len(raw_list) > 1:
                        parsed['args'] = str(raw_list[1])

            # CAS 3 : Le champ 'tool' contient les arguments collÃ©s
            # Ex: {"tool": "CLOSE_WINDOW Firefox"}
            elif isinstance(parsed, dict) and isinstance(parsed.get('tool'), str):
                t = parsed['tool'].strip()
                if " " in t and not parsed.get('args'):
                    first_word = t.split(' ')[0]
                    # On vÃ©rifie grossiÃ¨rement si le premier mot ressemble Ã  un outil (majuscules)
                    if first_word.isupper() and len(first_word) > 2:
                        print(f"  [BRAIN] ðŸ”§ Correction R1 (Split Tool/Args)", flush=True)
                        parsed['tool'] = first_word
                        parsed['args'] = t[len(first_word):].strip()

            # CAS 4 : Hallucination d'outil (Correction Ã  la volÃ©e)
            # Si R1 invente "DEL_WINDOW" ou "STOP_PROGRAM" -> On force CLOSE_WINDOW
            if isinstance(parsed, dict):
                tool_check = str(parsed.get('tool', '')).upper()
                if tool_check in ["DEL_WINDOW", "DELETE_WINDOW", "STOP_PROGRAM", "KILL_APP", "KILL_WINDOW"]:
                    print(f"  [BRAIN] ðŸ”§ Correction Hallucination Outil: {tool_check} -> CLOSE_WINDOW", flush=True)
                    parsed['tool'] = "CLOSE_WINDOW"

            print(f"{'-'*20} [DEBUG] JSON FINAL {'-'*20}\n{json.dumps(parsed, indent=2, ensure_ascii=False)}\n{'='*58}", flush=True)
        # -------------------------------------------------------------

        if error:
            print(f"  [BRAIN] Ã‰chec parsing : {error}", flush=True)
            return fallback_intent_detection(user_input)
        
        # === FILTRE ANTI-HALLUCINATION SPÃ‰CIAL MÃ‰TÃ‰O ===
        if isinstance(parsed, dict) and parsed.get('tool') == 'WEATHER':
            arg_city = str(parsed.get('args', '')).strip()
            if arg_city and len(arg_city) > 2:
                user_clean = igor_config.remove_accents(user_input.lower())
                city_clean = igor_config.remove_accents(arg_city.lower())
                if city_clean not in user_clean:
                    print(f"  [ANTI-HALLUCINATION] Suppression de la ville inventÃ©e : '{arg_city}'", flush=True)
                    parsed['args'] = ""

        # === VALIDATION FINALE ===
        if isinstance(parsed, list):
            for item in parsed:
                if not isinstance(item, dict) or 'tool' not in item:
                    print(f"  [BRAIN] Item BATCH invalide: {item}", flush=True)
                    return fallback_intent_detection(user_input)
            
            print(f"  [BRAIN] âœ… BATCH dÃ©tectÃ© ({len(parsed)} actions)", flush=True)
            return "BATCH", parsed
        
        elif isinstance(parsed, dict) and 'tool' in parsed:
            parsed = force_batch_if_needed(user_input, parsed)

            if isinstance(parsed, list):
                print(f"  [BRAIN] âœ… BATCH corrigÃ© automatiquement ({len(parsed)} actions)", flush=True)
                return "BATCH", parsed

            tool_name = str(parsed['tool'])
            args_val = str(parsed.get('args', ''))
            
            print(f"  [BRAIN] âœ… Action unique: {tool_name}", flush=True)
            return tool_name, args_val
        
        else:
            print(f"  [BRAIN] Format JSON invalide: {type(parsed)}", flush=True)
            return fallback_intent_detection(user_input)
    
    except Exception as e:
        print(f"  [BRAIN] Exception : {e}")
        return "CHAT", "Je bugue un peu lÃ ."

def log_query_stats(source, intent=None):
    """Log les statistiques d'utilisation (pour optimisation future)"""
    igor_globals.STATS[source] += 1
    if intent:
        igor_globals.STATS["intents"][intent] = igor_globals.STATS["intents"].get(intent, 0) + 1

def print_stats():
    """Affiche les stats de performance (appeler en debug)"""
    total = sum([igor_globals.STATS["heuristic_hits"], igor_globals.STATS["cache_hits"], igor_globals.STATS["ai_calls"]])
    if total == 0:
        return
    
    print("\n=== STATISTIQUES BRAIN ===")
    print(f"Heuristiques: {igor_globals.STATS['heuristic_hits']} ({igor_globals.STATS['heuristic_hits']/total*100:.1f}%)")
    print(f"Cache: {igor_globals.STATS['cache_hits']} ({igor_globals.STATS['cache_hits']/total*100:.1f}%)")
    print(f"Appels IA: {igor_globals.STATS['ai_calls']} ({igor_globals.STATS['ai_calls']/total*100:.1f}%)")
    print(f"\nIntents dÃ©tectÃ©s: {igor_globals.STATS['intents']}")
    print("==========================\n")

def quick_heuristic_check(user_input):
    """
    PRÃ‰-filtre AVANT brain_query pour les cas ULTRA Ã©vidents.
    PRIORITÃ‰ ABSOLUE : Distinction Projets Igor vs Fichiers SystÃ¨me.
    """
    log_query_stats("heuristic_hits")
    
    lower = user_input.lower().strip()
    
    # === PRIORITÃ‰ 0 : PROJETS IGOR (AVANT TOUT) ===
    # Mots-clÃ©s qui indiquent clairement qu'on parle d'un PROJET Igor
    project_keywords = [
        "projet", "project", "siteweb", "code", "todo", 
        "sauvegarde", "fichier du projet", "dans le projet",
        "mon projet", "le projet", "projet actif"
    ]
    
    # âœ… NOUVEAU : DÃ©tection STRICTE du contexte projet
    has_project_context = any(kw in lower for kw in project_keywords)
    
    # Si on mentionne explicitement un projet, on NE FAIT PAS d'heuristique
    if has_project_context:
        print(f"  [QUICK] ðŸŽ¯ Contexte PROJET dÃ©tectÃ© â†’ Laisse l'IA gÃ©rer", flush=True)
        return None  # Laisse l'IA dÃ©cider (elle a le contexte des projets)
    
    # DÃ©tection explicite de la demande de vitesse pour la vision
    if ("vite" in lower or "rapide" in lower) and ("regarde" in lower or "vision" in lower):
            if "Ã©cran" in lower or "screen" in lower:
                print(f"  [QUICK] Vision Rapide (Ã‰cran) dÃ©tectÃ©e", flush=True)
                return ("VISION", "vite screen")
            elif "photo" in lower or "webcam" in lower:
                 print(f"  [QUICK] Vision Rapide (Webcam) dÃ©tectÃ©e", flush=True)
                 return ("VISION", "vite webcam")

    # === PRIORITÃ‰ 0.5 : VISION (QUESTIONS CONTEXTUELLES) ===
    # Capture "Qu'est-ce que tu vois ?", "Que vois-tu ?", "DÃ©cris ce que tu vois"
    # Placez ceci AVANT les fichiers pour Ã©viter que "Regarde..." ne soit pris pour OpenFile
    if "vois" in lower or "regarde" in lower:
         # Si combinÃ© avec "tu", "ce que", "qu'est-ce", "que" (Question visuelle)
         if any(w in lower for w in ["tu", "ce que", "qu'est-ce", "que", "ton", "tes"]):
             # Exclusion des fichiers explicites pour Ã©viter "Regarde le fichier X"
             if not any(w in lower for w in ["fichier", "dossier", "document", "projet"]):
                 print(f"  [QUICK] ðŸ‘ï¸ Vision contextuelle dÃ©tectÃ©e -> VISION", flush=True)
                 # On passe l'input entier pour que tool_vision_look dÃ©tecte "moi"/"webcam" ou "Ã©cran"
                 return ("VISION", user_input)

    # === PRIORITÃ‰ 1 : RECHERCHE DE FICHIERS (FIND) ===
    # Verbes de recherche (PAS d'ouverture)
    search_verbs = ["trouve", "cherche", "oÃ¹ est", "localise", "locate", "find"]
    
    has_search_verb = any(lower.startswith(v) or f" {v} " in lower for v in search_verbs)
    
    if has_search_verb:
        # Extensions pour dÃ©tecter qu'on parle d'un fichier
        file_extensions = [".pdf", ".jpg", ".jpeg", ".png", ".doc", ".txt", ".html", 
                          ".py", ".js", ".css", ".mp4", ".zip"]
        
        has_extension = any(ext in lower for ext in file_extensions)
        mentions_file = "fichier" in lower or "file" in lower
        
        # Si on cherche clairement un fichier
        if has_extension or mentions_file:
            # Extraction du nom de fichier
            clean_query = lower
            for verb in search_verbs:
                clean_query = clean_query.replace(verb, "", 1).strip()
            
            # Nettoyage articles
            for article in ["le ", "la ", "les ", "un ", "une ", "mon ", "ma ", "mes "]:
                if clean_query.startswith(article):
                    clean_query = clean_query[len(article):].strip()
            
            # Nettoyage mots parasites
            for noise in ["fichier ", "file ", "nommÃ© ", "appelÃ© "]:
                clean_query = clean_query.replace(noise, "").strip()
            
            print(f"  [QUICK] ðŸ” RECHERCHE FICHIER dÃ©tectÃ©e: '{clean_query}'", flush=True)
            return ("FIND", clean_query)

    # === PRIORITÃ‰ 1.5 : LECTURE DE NOTE (INTERCEPTION CRITIQUE) ===
    # EmpÃªche OPEN_FILE de voler "montre la note" en pensant que c'est un fichier
    if "note" in lower:
        note_verbs = ["montre", "lis", "voir", "affiche", "donne", "quelle est"]
        has_note_verb = any(v in lower for v in note_verbs)
        
        # Si on demande de lire une note ET qu'il n'y a pas d'extension (.txt) explicite
        if has_note_verb and not any(ext in lower for ext in [".txt", ".md", ".pdf", ".doc"]):
            print(f"  [QUICK] ðŸ“ LECTURE NOTE dÃ©tectÃ©e (Prioritaire): '{user_input}'", flush=True)
            return ("READ_NOTE", user_input)

    # === PRIORITÃ‰ 1.55 : MÃ‰MOIRE LONG TERME (MEM) ===
    # Capture "Retiens que...", "Sache que..." pour les faits durables
    if lower.startswith("retiens que ") or lower.startswith("sache que ") or lower.startswith("mÃ©morise que "):
        # Nettoyage : on garde tout ce qui suit "que "
        # Ex: "Retiens que ma couleur est bleue" -> "ma couleur est bleue"
        match = re.search(r"(?:retiens|sache|mÃ©morise)\s+que\s+(.+)", user_input, re.IGNORECASE)
        if match:
            fact = match.group(1).strip()
            print(f"  [QUICK] ðŸ§  MÃ©moire dÃ©tectÃ©e : '{fact}'", flush=True)
            return ("MEM", fact)

    # === PRIORITÃ‰ 1.6 : Ã‰CRITURE DE NOTE (HEURISTIQUE) ===
    # Capture "Note acheter du pain", "Note que je dois..."
    # On utilise startswith pour Ã©viter de capturer "La note est de 10"
    if lower.startswith("note ") or lower.startswith("noter ") or lower.startswith("ajoute une note"):
        # Nettoyage intelligent : on retire le verbe et les conjonctions de dÃ©but
        # Regex: ^(note|noter|ajoute une note) (que|de|d'|ceci|:)?
        clean_text = re.sub(r"^(?:note|noter|ajoute\s+une\s+note)\s*(?:que|qu'|de|d'|ceci|:)?\s*", "", user_input, flags=re.IGNORECASE).strip()
        
        if clean_text:
            print(f"  [QUICK] ðŸ“ Ã‰criture note dÃ©tectÃ©e : '{clean_text}'", flush=True)
            return ("NOTE", clean_text)
    
    # === PRIORITÃ‰ 2 : OUVERTURE DE FICHIERS (OPEN_FILE) ===
    # Verbes d'ouverture
    # AJOUT : "lance", "dÃ©marre" pour gÃ©rer "lance le fichier X"
    open_verbs = ["ouvre", "affiche", "montre", "lis", "regarde", "open", "show", "voir", "lance", "dÃ©marre"]
    
    has_open_verb = any(lower.startswith(v) or f" {v} " in lower for v in open_verbs)
    
    if has_open_verb:
        # Mots-clÃ©s qui indiquent qu'on parle d'un DOSSIER SYSTÃˆME
        system_folders = ["documents", "downloads", "tÃ©lÃ©chargements", "bureau", 
                         "desktop", "images", "photos", "pictures", "vidÃ©os", 
                         "videos", "musique", "music"]
        
        # Extensions de fichiers courantes
        file_extensions = [".pdf", ".jpg", ".jpeg", ".png", ".gif", ".mp4", ".avi", 
                          ".mkv", ".doc", ".docx", ".xls", ".xlsx", ".ppt", ".txt", 
                          ".zip", ".rar", ".odt", ".ods", ".csv"]

        # AJOUT : Mots-clÃ©s explicites de type fichier
        explicit_file_types = ["document", "fichier", "file", "image", "photo", "dessin", 
                              "scan", "feuille", "pdf", "texte", "note"]
        
        has_extension = any(ext in lower for ext in file_extensions)
        has_system_folder = any(folder in lower for folder in system_folders)
        has_explicit_type = any(ft in lower for ft in explicit_file_types)
        
        # VÃ©rifie si c'est probablement un fichier de projet (pour Ã©viter les conflits)
        current_project = skills.MEMORY.get('current_project')
        likely_project_file = (
            current_project 
            and has_extension 
            and not has_system_folder
        )
        
        # CONDITION Ã‰LARGIE : Si dossier systÃ¨me OU extension OU mot clÃ© "document/fichier"
        if has_extension or has_system_folder or has_explicit_type:
            clean_query = lower
            
            # On retire le verbe
            for verb in open_verbs:
                clean_query = clean_query.replace(verb, "", 1).strip()
            
            # On retire les dÃ©terminants
            for article in ["le ", "la ", "les ", "un ", "une ", "mon ", "ma ", "mes ", "ton ", "ta ", "tes ", "ce ", "cet ", "cette "]:
                if clean_query.startswith(article):
                    clean_query = clean_query[len(article):].strip()
            
            # Note : On laisse le mot "document" ou "stickman" ici, 
            # car tool_open_file (dans igor_system) fera son propre nettoyage final.
            
            print(f"  [QUICK] ðŸŽ¯ FICHIER dÃ©tectÃ© (Heuristique): '{clean_query}' -> OPEN_FILE", flush=True)
            return ("OPEN_FILE", clean_query)
        
        # Cas ambigu : projet actif
        elif likely_project_file:
            print(f"  [QUICK] âš ï¸ AmbiguÃ¯tÃ© (Projet: {current_project}) â†’ IA", flush=True)
            return None
    
    # === PRIORITÃ‰ IDENTITÃ‰ : QUESTIONS (CHAT) ===
    # On gÃ¨re ici les demandes d'information (ex: "C'est quoi ton nom", "Ton nom est ?")
    
    # 1. QUESTION SUR L'USER ("C'est quoi mon nom ?", "Mon nom est ?")
    regex_question_user = re.compile(
        r"^(?:quel\s+est|c'est\s+quoi|dis(?:[-\s]moi)?|donne(?:[-\s]moi)?|rappell?e(?:[-\s]moi)?)\s+mon\s+(?:nom|prÃ©nom)|"
        r"comment\s+je\s+m['\s]appelle|"
        r"qui\s+suis[-\s]je|"
        r"^mon\s+(?:pre)?nom\s+est\s*[?]?$", # Capture "Mon nom est ?" (vide aprÃ¨s)
        re.IGNORECASE
    )
    if regex_question_user.search(lower):
        user_n = skills.MEMORY.get('user_name', 'Utilisateur')
        print(f"  [QUICK] â“ Question identitÃ© user -> CHAT", flush=True)
        return ("CHAT", f"Tu t'appelles {user_n}.")

    # 2. QUESTION SUR L'AGENT ("C'est quoi ton nom ?", "Ton nom est ?")
    regex_question_agent = re.compile(
        r"^(?:quel\s+est|c'est\s+quoi|dis(?:[-\s]moi)?|donne(?:[-\s]moi)?)\s+ton\s+(?:nom|prÃ©nom)|"
        r"comment\s+tu\s+t['\s]appelles?|"
        r"qui\s+es[-\s]tu|t'es\s+qui|"
        r"^ton\s+(?:pre)?nom\s+est\s*[?]?$", # Capture "Ton nom est ?" (vide aprÃ¨s)
        re.IGNORECASE
    )
    if regex_question_agent.search(lower):
        agent_n = skills.MEMORY.get('agent_name', 'Igor')
        print(f"  [QUICK] â“ Question identitÃ© agent -> CHAT", flush=True)
        return ("CHAT", f"Je m'appelle {agent_n}.")

    # === PRIORITÃ‰ IDENTITÃ‰ : COMMANDES (CHANGEMENT DE NOM) ===
    
    # 3. CHANGER LE NOM DE L'UTILISATEUR ("Je m'appelle Jambon", "Mon nom est Jambon")
    # Regex stricte : Doit commencer par JE/MON et avoir du contenu aprÃ¨s.
    regex_set_username = re.compile(
        r"^(?:je\s+(?:suis|m['\s]appelle)|mon\s+(?:pre)?nom\s+est|appelle[\s-]moi)\s+(?P<name>.+)$",
        re.IGNORECASE
    )
    match_user = regex_set_username.match(lower)
    if match_user:
        new_name = match_user.group("name").strip()
        # Petit nettoyage si l'user dit "je m'appelle le grand X"
        for noise in ["le ", "la ", "un "]: 
             if new_name.startswith(noise): new_name = new_name[len(noise):]
        
        print(f"  [QUICK] ðŸ†” Changement nom USER dÃ©tectÃ© : '{new_name}' -> USERNAME", flush=True)
        return ("USERNAME", new_name)

    # 4. CHANGER LE NOM DE L'AGENT ("Tu t'appelles Igor", "Ton nom est Igor")
    # Regex stricte : Doit commencer par TU/TON et avoir du contenu aprÃ¨s.
    regex_set_agentname = re.compile(
        r"^(?:tu\s+(?:es|t['\s]appelles?)|ton\s+(?:pre)?nom\s+est|appelle[\s-]toi|change\s+ton\s+nom\s+(?:en|pour))\s+(?P<name>.+)$",
        re.IGNORECASE
    )
    match_agent = regex_set_agentname.match(lower)
    if match_agent:
        new_name = match_agent.group("name").strip()
        # Petit nettoyage
        for noise in ["le ", "la ", "un "]:
             if new_name.startswith(noise): new_name = new_name[len(noise):]

        print(f"  [QUICK] ðŸ†” Changement nom AGENT dÃ©tectÃ© : '{new_name}' -> AGENTNAME", flush=True)
        return ("AGENTNAME", new_name)

    # === PRIORITÃ‰ 2.1 : ALARME (COMMANDES EXPLICITES) ===
    # Capture "RÃ©veille-moi Ã ...", "Mets une alarme...", "Debout Ã  8h"
    alarm_triggers = ["alarme", "reveil", "rÃ©veil", "sonnerie", "debout"]
    if any(k in lower for k in alarm_triggers):
        
        # 1. DÃ‰TECTION SUPPRESSION (PRIORITÃ‰ ABSOLUE)
        # Si on voit "supprime", "efface", "retire" + alarme -> DEL_ALARM
        del_keywords = ["supprime", "efface", "retire", "enleve", "enlÃ¨ve", "annule", "arrete", "arrÃªte", "stop"]
        if any(w in lower for w in del_keywords):
            print(f"  [QUICK] ðŸ—‘ï¸ Suppression alarme dÃ©tectÃ©e -> DEL_ALARM: '{user_input}'", flush=True)
            return ("DEL_ALARM", user_input)

        # 2. DÃ‰TECTION CRÃ‰ATION
        # On vÃ©rifie la prÃ©sence d'une indication temporelle (chiffres ou mots temporels)
        time_indicators = ["dans", "Ã ", "a ", "pour", "minutes", "heures", "h", "min", "sec", "demain", "matin", "soir", "midi", "minuit"]
        has_time = any(t in lower for t in time_indicators) or any(char.isdigit() for char in lower)
        
        # Exclusion des commandes de configuration ("change la sonnerie")
        is_config = any(s in lower for s in ["change", "rÃ¨gle", "defin", "choisi", "style", "type", "bruit", "son"])
        
        if has_time and not is_config:
             print(f"  [QUICK] â° Alarme dÃ©tectÃ©e -> ALARM: '{user_input}'", flush=True)
             return ("ALARM", user_input)

    # === PRIORITÃ‰ 2.2 : RAPPELS (AmbiguÃ¯tÃ© Alarme vs Note) ===
    # Gestion de : "Rappelle-moi Ã  8h" (Alarme) vs "Rappelle-moi de manger" (Note)
    if "rappel" in lower:
        # 1. DÃ©tection temporelle (C'est une alarme)
        time_triggers = ["dans", "Ã ", "pour", "minutes", "heures", "h", "min", "sec", "demain"]
        has_time = any(t in lower for t in time_triggers) or any(char.isdigit() for char in lower)

        if has_time:
             print(f"  [QUICK] â° Rappel temporel dÃ©tectÃ© -> ALARM", flush=True)
             return ("ALARM", user_input)

        # 2. Sinon, c'est une Note (To-Do)
        # Nettoyage de l'ordre "Rappelle moi de" pour ne garder que le contenu
        clean_text = re.sub(r"^(?:se\s+)?rappell?ez?(?:[-\s]moi)?\s*(?:de|d')?\s*", "", user_input, flags=re.IGNORECASE).strip()
        
        if clean_text:
            print(f"  [QUICK] ðŸ“ Rappel tÃ¢che dÃ©tectÃ© -> NOTE: '{clean_text}'", flush=True)
            return ("NOTE", clean_text)

    # === PRIORITÃ‰ 2.3 : GESTION TODO LIST (Done/Add) ===
    # DÃ©tection explicite pour Ã©viter la confusion avec CONFIG ("met")
    if "todo" in lower or "tache" in lower or "tÃ¢che" in lower:
        # 1. Marquer comme fait (Coche, Valide, Met Ã  fait, Fini, Done)
        # On cherche des mots clÃ©s de validation ET un chiffre
        validation_keywords = ["fait", "done", "fini", "coche", "valide", "met", "marqu"]
        if any(w in lower for w in validation_keywords) and any(char.isdigit() for char in lower):
             # Extraction du numÃ©ro (ex: "point 2" -> "2")
             nums = re.findall(r'\d+', user_input)
             if nums:
                 idx = nums[0] # On prend le premier chiffre trouvÃ©
                 print(f"  [QUICK] âœ… Validation TÃ¢che dÃ©tectÃ©e -> PROJECT_TODO_DONE: '{idx}'", flush=True)
                 return ("PROJECT_TODO_DONE", idx)

    # === PRIORITÃ‰ 2.5 : Commandes Muet/Parole (REGEX ROBUSTE) ===
    # DÃ©tecte: "parle Ã  nouveau", "tu peux parler", "remets le son", "active la voix", "sors du mode muet", "dÃ©sactive le silencieux", etc.
    regex_unmute = re.compile(
        r"(?:tu\s+peux\s+|vas[- ]?y\s+|re)parl(?:e|er|es?)\b|"       # Tu peux parler, vas-y parle, reparle
        r"parl(?:e|er|es?)\s+(?:Ã |de)\s+nouveau|"                    # Parle Ã  nouveau
        r"(?:r?Ã©?activ|re?met|rÃ©tabl|allum)\w*\s+(?:le\s+|la\s+|ton\s+|ta\s+)?(?:son|voix|parole|audio)|" # Active/Remets le son/la voix
        r"(?:dÃ©sactiv|enlÃ¨ve|sor|quitt|coup)\w*\s+(?:le\s+|du\s+)?(?:mode\s+)?(?:muet|silencieux|silence)", # DÃ©sactive/Sors du mode muet
        re.IGNORECASE
    )

    if regex_unmute.search(lower):
        print(f"  [QUICK] Unmute dÃ©tectÃ© (Regex): {lower}", flush=True)
        return ("SET_MUTE", "off")

    # === PRIORITÃ‰ 2.6 : COMMANDES SHELL ===
    shell_triggers = [
        "exÃ©cute la commande", "execute la commande", 
        "commande terminal", "commande shell", 
        "lance la commande", "run command"
    ]
    
    if any(t in lower for t in shell_triggers):
        for trigger in shell_triggers:
            if trigger in lower:
                # Extraction commande (en gardant la casse)
                idx = lower.find(trigger) + len(trigger)
                cmd = user_input[idx:].strip().lstrip(":").strip()
                if cmd:
                    print(f"  [QUICK] SHELL dÃ©tectÃ©: '{cmd}'", flush=True)
                    return ("SHELL", cmd)

    # === PRIORITÃ‰ 3 : Commandes systÃ¨me (1 mot) ===
    direct_commands = {
        "stop": ("SET_MUTE", "on"),
        "silence": ("SET_MUTE", "on"),
        "tais-toi": ("SET_MUTE", "on"),
        "parle": ("SET_MUTE", "off"),
        "pause": ("MEDIA", "pause"),
        "play": ("MEDIA", "play"),
        "lecture": ("MEDIA", "play"),
        "next": ("MEDIA", "next"),
        "suivant": ("MEDIA", "next"),
        "piste suivante": ("MEDIA", "next"),
        "prÃ©cÃ©dent": ("MEDIA", "previous"),
        "piste prÃ©cÃ©dente": ("MEDIA", "previous"),
        "prev": ("MEDIA", "previous")
    }
    
    if lower in direct_commands:
        print(f"  [QUICK] Commande directe: {lower}", flush=True)
        return direct_commands[lower]
    
    # === PRIORITÃ‰ 4 : Questions systÃ¨me (REGEX) ===
    # Liste de tuples (Pattern Regex, Action)
    system_regexes = [
        # NOUVEAU : Ã‰tat du systÃ¨me / Stats (RAM, CPU, Disque)
        (r"(?:donne[- ]moi\s+|quel\s+est\s+)?l['\s]Ã©tat\s+du\s+systÃ¨me|stats?\s+systÃ¨me|system\s+status|usage\s+(?:cpu|ram|memoire)|performances?", ("SYSTEM_STATS", "")),

        # NOUVEAU : Statut de l'agent (Config, Alarmes, MÃ©moire interne)
        (r"(?:quel\s+est\s+)?(?:ton\s+)?statut|configuration|paramÃ¨tres?|diagnostic", ("STATUS", "")),

        # Apps: "Quelles apps", "Liste mes applications", "Logiciels installÃ©s"
        (r"(?:quelles?|liste|mes|voir)\s+(?:toutes\s+les\s+)?(?:applications?|apps?|logiciels?)", ("LIST_APPS", "")),
        
        # Windows: "Quelles fenÃªtres", "Liste fenÃªtres", "Qu'est-ce qui est ouvert"
        (r"(?:quelles?|liste)\s+(?:fenÃªtres?|windows?)|(?:applications?|fenÃªtres?)\s+ouvertes?|qu'est\s+ce\s+qui\s+est\s+ouvert", ("LIST_WINDOWS", "")),
        
        # Projects: "Mes projets", "Liste projets"
        (r"(?:quels?|liste|mes|voir)\s+projets?", ("PROJECT_LIST", "")),
        
        # Notes: "Lis mes notes", "Note #1"
        # MODIFICATION : On passe user_input pour capturer le numÃ©ro Ã©ventuel
        (r"(?:mes|liste|lis|voir|montre)\s+(?:mes\s+|la\s+)?notes?", ("READ_NOTE", user_input)),
        
        # Alarms: "Mes alarmes", "Quelles alarmes"
        (r"(?:mes|liste|quelles?|voir)\s+alarmes?", ("SHOW_ALARMS", "")),
        
        # Memory: "Que sais-tu SUR MOI", "Ta mÃ©moire", "Ce que tu sais DE MOI"
        # MODIFICATION : Ajout de (?:sur\s+moi|de\s+moi|me\s+concernant) pour ne pas intercepter "Que sais-tu des serpents"
        # Correction Regex : Supporte "que sais-tu", "qu'est-ce que tu sais", "ce que tu sais"
        (r"(?:qu'est\s+ce\s+que|que|ce\s+que)\s+(?:tu\s+sais|sais[-\s]tu)\s+(?:sur\s+moi|de\s+moi|me\s+concernant)|ta\s+mÃ©moire|faits?\s+mÃ©morisÃ©s?", ("READ_MEM", ""))
    ]

    for pattern, action in system_regexes:
        if re.search(pattern, lower):
            print(f"  [QUICK] Question systÃ¨me (Regex): {action[0]}", flush=True)
            return action
        
    # === PRIORITÃ‰ 4.5 : Vitesse de la voix (SPEED) ===
    # Liste Ã©largie pour inclure "vitesse normale", "parle vite", etc.
    speed_keywords = [
        "parle plus vite", "parle moins vite", "parle plus lentement", 
        "vitesse de la voix", "ralentis", "accÃ©lÃ¨re", 
        "vitesse normal", "vitesse normale", "remets la vitesse",
        "parle normalement"
    ]
    
    if any(k in lower for k in speed_keywords):
        print(f"  [QUICK] Vitesse voix dÃ©tectÃ©e : '{user_input}'", flush=True)
        return ("SET_SPEED", user_input)
        
    # Cas spÃ©cifique "parle doucement"
    if "parle" in lower and "doucement" in lower:
        return ("SET_SPEED", "doucement")

    # === PRIORITÃ‰ 5 : Musique ===
    # A. Demande de statut / Identification ("Qu'est-ce qui se passe en musique ?", "C'est quoi ce titre ?")
    music_status_triggers = [
        "se passe en musique", "joue en ce moment", "titre de la chanson", 
        "c'est quoi cette musique", "quelle est cette musique", "quelle musique joue",
        "qui chante", "c'est quoi ce son", "quel est ce titre", "niveau musique"
    ]
    
    if any(t in lower for t in music_status_triggers):
        print(f"  [QUICK] ðŸŽµ Statut Musique dÃ©tectÃ© -> MUSIC_CHECK (Passif)", flush=True)
        # On passe l'argument "status" pour empÃªcher Igor de lancer/pauser des trucs
        return ("MUSIC_CHECK", "status")

    # B. Commandes de lancement ("Mets de la musique")
    music_launch_triggers = [
        "mets de la musique", "met de la musique", "lance la musique",
        "joue de la musique", "play music", "de la musique",
        "mettre de la musique", "lancer de la musique"
    ]
    
    # Filtres nÃ©gatifs pour le lancement (Ã©viter les dÃ©finitions encyclopÃ©diques)
    music_negative = [
        "quelle", "quel", "c'est quoi", "qu'est-ce", "identifie", "reconnaÃ®t"
    ]
    
    # Si demande de musique SANS question d'identification
    if any(trigger in lower for trigger in music_launch_triggers):
        if not any(neg in lower for neg in music_negative):
            print(f"  [QUICK] ðŸŽµ Lancement MUSIQUE dÃ©tectÃ© -> MUSIC_CHECK", flush=True)
            return ("MUSIC_CHECK", "")
    
    # === PRIORITÃ‰ 6 : ContrÃ´le mÃ©dia ===
    control_phrases = [
        "en pause", "en lecture", "en plein Ã©cran", "plein Ã©cran", 
        "fullscreen", "volume", "son"
    ]
    
    if any(phrase in lower for phrase in control_phrases):
        return None  # Laisse l'IA gÃ©rer
    
    # === PRIORITÃ‰ 7 : Recettes de cuisine (SEARCH forcÃ©) ===
    # Force la recherche Web pour les recettes au lieu de la dÃ©finition (KNOWLEDGE)
    if "recette" in lower:
        print(f"  [QUICK] Recette cuisine dÃ©tectÃ©e -> SEARCH: '{user_input}'", flush=True)
        return ("SEARCH", user_input)

    # === PRIORITÃ‰ 8 : Gestion des Raccourcis (List/Delete) ===
    # On ajoute "raccouric" et "racourci" Ã  la liste de dÃ©tection
    if any(k in lower for k in ["raccourci", "raccouric", "racourci", "favori"]):
        
        # Cas 1 : Suppression
        if any(w in lower for w in ["supprime", "efface", "retire", "enlever"]):
            # Extraction propre du nom
            target = lower
            # On ajoute aussi les typos dans la liste des mots Ã  nettoyer
            for noise in ["supprime", "efface", "retire", "enlever", 
                          "le raccourci", "mon raccourci", "raccourci", 
                          "le raccouric", "raccouric", "racourci", 
                          "le favori", "favori"]:
                target = target.replace(noise, "")
            target = target.strip()
            
            print(f"  [QUICK] Suppression raccourci dÃ©tectÃ©e: '{target}'", flush=True)
            return ("SHORTCUT_DELETE", target)
            
        # Cas 2 : Liste / Consultation
        if any(w in lower for w in ["quels", "quelles", "liste", "mes", "voir", "montre"]):
            print(f"  [QUICK] Liste raccourcis dÃ©tectÃ©e", flush=True)
            return ("SHORTCUT_LIST", "")

    # === PRIORITÃ‰ 6 : YouTube ===
    if "sur youtube" in lower or "youtube" in lower:
        query = lower
        for verb in ["mets", "met", "lance", "joue", "regarde", "ouvre"]:
            query = query.replace(verb, "").strip()
        
        for noise in ["sur youtube", "youtube", "la", "le", "du", "de", "une", "un"]:
            query = query.replace(noise, "").strip()
        
        if len(query) > 2:
            youtube_arg = f"Youtube {query}"
            print(f"  [QUICK] Youtube dÃ©tectÃ©: '{youtube_arg}'", flush=True)
            return ("LAUNCH", youtube_arg)
    
    # === PRIORITÃ‰ 7 : VidÃ©os ===
    video_patterns = ["vidÃ©o de ", "video de ", "clip de ", "musique de "]
    for pattern in video_patterns:
        if pattern in lower:
            idx = lower.find(pattern)
            subject = lower[idx + len(pattern):].strip()
            
            for noise in ["la", "le", "du", "de", "une", "un"]:
                subject = subject.replace(noise, "").strip()
            
            if len(subject) > 2:
                youtube_arg = f"Youtube {subject}"
                print(f"  [QUICK] VidÃ©o dÃ©tectÃ©e: '{youtube_arg}'", flush=True)
                return ("LAUNCH", youtube_arg)
    
    # === PRIORITÃ‰ 8 : Nombres seuls ===
    if lower.isdigit():
        num = int(lower)
        if skills.LAST_WIKI_OPTIONS:
            print(f"  [QUICK] SÃ©lection Wiki #{num}", flush=True)
            return ("LEARN", lower)
        if 0 <= num <= 100:
            print(f"  [QUICK] Volume {num}", flush=True)
            return ("VOLUME", lower)
    
    # === PRIORITÃ‰ 9 : SÃ©lection Wikipedia ===
    if skills.LAST_WIKI_OPTIONS:
        selection_keywords = ["premier", "1er", "deuxiÃ¨me", "second", "2Ã¨me", "troisiÃ¨me", "3Ã¨me"]
        if any(k in lower for k in selection_keywords):
            print(f"  [QUICK] SÃ©lection contextuelle Wiki", flush=True)
            return ("LEARN", user_input)

    # === PRIORITÃ‰ 10 : MAXIMISATION / PLEIN Ã‰CRAN (Force l'outil FULLSCREEN) ===
    # On intercepte ici pour Ã©viter que l'IA n'invente MAXIMIZE_WINDOW
    if any(k in lower for k in ["maximise", "maximize", "agrandis", "plein Ã©cran", "fullscreen"]):
        # On vÃ©rifie que ce n'est pas une question ("c'est quoi le plein Ã©cran")
        if not any(k in lower for k in ["c'est quoi", "comment"]):
            print(f"  [QUICK] Maximisation dÃ©tectÃ©e -> FULLSCREEN", flush=True)
            return ("FULLSCREEN", user_input)

    # === PRIORITÃ‰ 11 : FOCUS FENÃŠTRE (NOUVEAU) ===
    if "focus" in lower:
        # Nettoyage simple pour extraire la cible
        target = lower.replace("focus", "").strip()
        # On enlÃ¨ve "sur" si prÃ©sent
        if target.startswith("sur "): target = target[4:].strip()
        
        if target:
            print(f"  [QUICK] Focus dÃ©tectÃ© -> FOCUS_WINDOW: '{target}'", flush=True)
            return ("FOCUS_WINDOW", target)
    
    return None  # Pas de match â†’ Appel IA nÃ©cessaire

def get_cached_or_query(user_input):
    """
    VÃ©rifie le cache avant d'appeler l'IA.
    Utilise un hash MD5 de la requÃªte comme clÃ©.
    """
    # Hash de la requÃªte (insensible Ã  la casse)
    cache_key = hashlib.md5(user_input.lower().encode()).hexdigest()
    
    if cache_key in igor_globals.QUERY_CACHE:
        log_query_stats("cache_hits")
        print(f"  [CACHE HIT] RÃ©ponse instantanÃ©e", flush=True)
        return igor_globals.QUERY_CACHE[cache_key]
    
    # Appel IA
    result = brain_query(user_input)
    log_query_stats("ai_calls")
    
    # Sauvegarde cache (avec limite de taille FIFO)
    if len(igor_globals.QUERY_CACHE) >= igor_globals.CACHE_MAX_SIZE:
        # Supprime la plus ancienne entrÃ©e
        igor_globals.QUERY_CACHE.pop(next(iter(igor_globals.QUERY_CACHE)))
    
    igor_globals.QUERY_CACHE[cache_key] = result
    return result